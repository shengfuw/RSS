{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "from typing import NewType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 資料型態必須是 [年,[電影,電影...],年,[電影,電影...]...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_informationget(filename,type_name):#(讀到的json檔,這個list類型的名字)\n",
    "    with open(filename) as f:\n",
    "        result=json.load(f)\n",
    "    movielist=[]\n",
    "    i=1\n",
    "    for m in result:\n",
    "        if i/2==1:\n",
    "            movielist.extend(m)\n",
    "            i=0\n",
    "        i+=1\n",
    "    print(\"%s%d%s\" % (\"共有\",len(movielist),\"片電影\"))\n",
    "    movie_home={}\n",
    "    movie_plotsummary={}\n",
    "    movie_keywords={}\n",
    "    pre = 'https://www.imdb.com/find?ref_=nv_sr_fn&q='\n",
    "    for movie in movielist:\n",
    "        url = pre+movie\n",
    "        results = requests.get(url)\n",
    "        soup = BeautifulSoup(results.text, 'html.parser')\n",
    "        for tr in soup.find_all(class_=\"findResult odd\")[:1]:\n",
    "            a=\"https://www.imdb.com\"\n",
    "            b=tr.a.attrs['href'][:17]\n",
    "            movie_home[movie]=a+b\n",
    "            movie_plotsummary[movie]=a+b+\"plotsummary\"\n",
    "            movie_keywords[movie]=a+b+\"keywords\"   \n",
    "    with open(type_name+'_homeURL.json','w') as outfile:\n",
    "        json.dump(movie_home,outfile)\n",
    "    with open(type_name+'_plotsummaryURL.json','w') as outfile:\n",
    "        json.dump(movie_plotsummary,outfile)\n",
    "    with open(type_name+'_keywordsURL.json','w') as outfile:\n",
    "        json.dump(movie_keywords,outfile)\n",
    "    print(\"URLget completed\")\n",
    "    \n",
    "    plotsummary={}\n",
    "    b=[]\n",
    "    for movie in movielist:\n",
    "        try:\n",
    "            url = movie_plotsummary[movie]\n",
    "        except:\n",
    "            continue\n",
    "        results = requests.get(url)\n",
    "        soup = BeautifulSoup(results.text, 'html.parser')\n",
    "        for li in soup.find_all(class_=\"ipl-zebra-list__item\"):\n",
    "                try:\n",
    "                    a=li.p.string\n",
    "                    if a != None:\n",
    "                        b.append(a)\n",
    "                except:\n",
    "                    None\n",
    "        plotsummary[movie]=b\n",
    "    with open(type_name+'_plotsummary.json','w') as outfile:\n",
    "        json.dump(plotsummary,outfile)\n",
    "    print(\"plotsummaryget completed\")\n",
    "    \n",
    "    keywords={}\n",
    "    b=[]\n",
    "    for movie in movielist:\n",
    "        try:\n",
    "            url = movie_keywords[movie]\n",
    "        except:\n",
    "            continue\n",
    "        results = requests.get(url)\n",
    "        soup = BeautifulSoup(results.text, 'html.parser')\n",
    "        for div in soup.find_all(class_=\"sodatext\"):\n",
    "            b.append(div.a.string)\n",
    "        keywords[movie]=b\n",
    "    with open(type_name+'_keywords.json','w') as outfile:\n",
    "        json.dump(keywords,outfile)\n",
    "    print(\"keywordsget completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有333片電影\n",
      "URLget completed\n",
      "plotsummarygetget completed\n",
      "keywordsget completed\n"
     ]
    }
   ],
   "source": [
    "movie_informationget('lgbt-related_movielist.json','lgbt-related')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有139片電影\n",
      "URLget completed\n",
      "plotsummarygetget completed\n",
      "keywordsget completed\n"
     ]
    }
   ],
   "source": [
    "movie_informationget('racism-related_movielist.json','racism-related')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 資料型態必須是[電影,電影,電影...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_informationget1(filename,type_name):#(讀到的json檔,這個list類型的名字)\n",
    "    with open(filename) as f:\n",
    "        movielist=json.load(f)\n",
    "    print(\"%s%d%s\" % (\"共有\",len(movielist),\"片電影\"))\n",
    "    movie_home={}\n",
    "    movie_plotsummary={}\n",
    "    movie_keywords={}\n",
    "    pre = 'https://www.imdb.com/find?ref_=nv_sr_fn&q='\n",
    "    for movie in movielist:\n",
    "        url = pre+movie\n",
    "        results = requests.get(url)\n",
    "        soup = BeautifulSoup(results.text, 'html.parser')\n",
    "        for tr in soup.find_all(class_=\"findResult odd\")[:1]:\n",
    "            a=\"https://www.imdb.com\"\n",
    "            b=tr.a.attrs['href'][:17]\n",
    "            movie_home[movie]=a+b\n",
    "            movie_plotsummary[movie]=a+b+\"plotsummary\"\n",
    "            movie_keywords[movie]=a+b+\"keywords\"   \n",
    "    with open(type_name+'_homeURL.json','w') as outfile:\n",
    "        json.dump(movie_home,outfile)\n",
    "    with open(type_name+'_plotsummaryURL.json','w') as outfile:\n",
    "        json.dump(movie_plotsummary,outfile)\n",
    "    with open(type_name+'_keywordsURL.json','w') as outfile:\n",
    "        json.dump(movie_keywords,outfile)\n",
    "    print(\"URLget completed\")\n",
    "    \n",
    "    plotsummary={}\n",
    "    b=[]\n",
    "    for movie in movielist:\n",
    "        try:\n",
    "            url = movie_plotsummary[movie]\n",
    "        except:\n",
    "            continue\n",
    "        results = requests.get(url)\n",
    "        soup = BeautifulSoup(results.text, 'html.parser')\n",
    "        for li in soup.find_all(class_=\"ipl-zebra-list__item\"):\n",
    "                try:\n",
    "                    a=li.p.string\n",
    "                    if a != None:\n",
    "                        b.append(a)\n",
    "                except:\n",
    "                    None\n",
    "        plotsummary[movie]=b\n",
    "    with open(type_name+'_plotsummary.json','w') as outfile:\n",
    "        json.dump(plotsummary,outfile)\n",
    "    print(\"plotsummaryget completed\")\n",
    "    \n",
    "    keywords={}\n",
    "    b=[]\n",
    "    for movie in movielist:\n",
    "        try:\n",
    "            url = movie_keywords[movie]\n",
    "        except:\n",
    "            continue\n",
    "        results = requests.get(url)\n",
    "        soup = BeautifulSoup(results.text, 'html.parser')\n",
    "        for div in soup.find_all(class_=\"sodatext\"):\n",
    "            b.append(div.a.string)\n",
    "        keywords[movie]=b\n",
    "    with open(type_name+'_keywords.json','w') as outfile:\n",
    "        json.dump(keywords,outfile)\n",
    "    print(\"keywordsget completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有250片電影\n",
      "URLget completed\n",
      "plotsummaryget completed\n",
      "keywordsget completed\n"
     ]
    }
   ],
   "source": [
    "movie_informationget1('top250_movielist.json','top205')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
